{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e9dae77",
   "metadata": {},
   "source": [
    "Librerias Necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e682c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981d7e4",
   "metadata": {},
   "source": [
    "Funciones a Utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13209a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_imagenes(carpeta, label):\n",
    "    datos_imagenes = []\n",
    "    archivos = sorted(os.listdir(carpeta))\n",
    "    for nombre_archivo in archivos:\n",
    "        if nombre_archivo.endswith(\".png\"):\n",
    "            path = os.path.join(carpeta, nombre_archivo)\n",
    "            imagen = plt.imread(path)  # Cargar la imagen como array\n",
    "            datos_imagenes.append((label, imagen))\n",
    "    return datos_imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b68ab51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abiab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\abiab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Preprocesamiento como espera ResNet (ImagenNet)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Tamaño estándar para ResNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Valores de ImageNet\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Modelo ResNet18 sin capa final de clasificación\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # Quitar capa FC final\n",
    "resnet.eval()\n",
    "\n",
    "def generar_embeddings(carpeta_entrada, label='Default'):\n",
    "    if not os.path.exists(carpeta_entrada):\n",
    "        raise FileNotFoundError(f'La carpeta {carpeta_entrada} no existe.')\n",
    "    \n",
    "    datos_imagenes = cargar_imagenes(carpeta_entrada, label)\n",
    "    embeddings = []\n",
    "    for nombre, imagen in datos_imagenes:\n",
    "        # Asegurar formato correcto\n",
    "        if imagen.dtype != np.uint8:\n",
    "            imagen = (imagen * 255).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "        if len(imagen.shape) == 2:\n",
    "            # Escala de grises → convertir a RGB\n",
    "            imagen = cv2.cvtColor(imagen, cv2.COLOR_GRAY2RGB)\n",
    "        elif imagen.shape[-1] == 4:\n",
    "            # RGBA → eliminar canal alfa\n",
    "            imagen = imagen[:, :, :3]\n",
    "\n",
    "        # Convertir a PIL.Image\n",
    "        imagen_pil = Image.fromarray(imagen)\n",
    "\n",
    "        # Transformar y generar embedding\n",
    "        imagen_tensor = transform(imagen_pil).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            emb = resnet(imagen_tensor).squeeze().numpy()\n",
    "\n",
    "        embeddings.append((label, emb))\n",
    "    \n",
    "    return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3121e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_val_vector(imagen): # Recibe imagen BGR o Gray\n",
    "    # --- Preparar imagen ---\n",
    "    if len(imagen.shape) == 3 and imagen.shape[2] == 3:\n",
    "        img_gray = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "        img_hsv = cv2.cvtColor(imagen, cv2.COLOR_BGR2HSV)\n",
    "    else:\n",
    "        img_gray = imagen\n",
    "        img_hsv = None\n",
    "\n",
    "    total_pixeles = img_gray.size\n",
    "\n",
    "    # 1. Media de intensidad\n",
    "    media = np.mean(img_gray)\n",
    "\n",
    "    # 2. Desviación estándar de intensidad\n",
    "    std = np.std(img_gray)\n",
    "\n",
    "    # 3–6. Histograma reducido (4 bins)\n",
    "    hist, _ = np.histogram(img_gray, bins=4, range=(0, 256), density=True)\n",
    "    hist = hist.tolist()\n",
    "\n",
    "    # 7. Porcentaje de pixeles oscuros (< 50)\n",
    "    porc_oscuro = np.sum(img_gray < 50) / total_pixeles\n",
    "\n",
    "    # 8. Porcentaje de pixeles claros (> 200)\n",
    "    porc_claro = np.sum(img_gray > 200) / total_pixeles\n",
    "\n",
    "    # 9. Densidad de bordes (Canny)\n",
    "    img_gray = img_gray.astype(np.uint8)\n",
    "    bordes = cv2.Canny(img_gray, 100, 200)\n",
    "    dens_bordes = np.sum(bordes > 0) / total_pixeles\n",
    "\n",
    "    # 10. Número de componentes conectados (Otsu)\n",
    "    # --- Convertir imagen a escala de grises si tiene más de 1 canal ---\n",
    "    if len(imagen.shape) == 3:\n",
    "        if imagen.shape[2] == 4:  # RGBA\n",
    "            imagen = imagen[:, :, :3]  # eliminar canal alfa\n",
    "        img_gray = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        img_gray = imagen\n",
    "    # Asegurar tipo uint8\n",
    "    if img_gray.dtype != np.uint8:\n",
    "        img_gray = (img_gray * 255).clip(0, 255).astype(np.uint8)\n",
    "    _, binarizada = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    n_labels, labels = cv2.connectedComponents(binarizada)\n",
    "    num_componentes = n_labels - 1  # sin contar el fondo\n",
    "\n",
    "    # 11. Área del componente más grande (excluyendo fondo)\n",
    "    if num_componentes > 0:\n",
    "        stats = cv2.connectedComponentsWithStats(binarizada)[2]\n",
    "        area_max = np.max(stats[1:, cv2.CC_STAT_AREA])\n",
    "    else:\n",
    "        area_max = 0\n",
    "\n",
    "    # 12–13. Centroide de masa (normalizado)\n",
    "    masa_total = np.sum(img_gray)\n",
    "    if masa_total > 0:\n",
    "        y_indices, x_indices = np.indices(img_gray.shape)\n",
    "        cx = np.sum(x_indices * img_gray) / masa_total\n",
    "        cy = np.sum(y_indices * img_gray) / masa_total\n",
    "        cx /= img_gray.shape[1]\n",
    "        cy /= img_gray.shape[0]\n",
    "    else:\n",
    "        cx = cy = 0.5\n",
    "\n",
    "    # 14. Razón de aspecto\n",
    "    razon_aspecto = img_gray.shape[1] / img_gray.shape[0]\n",
    "\n",
    "    # 15. Color dominante (modo del canal H de HSV)\n",
    "    if img_hsv is not None:\n",
    "        hist_h = cv2.calcHist([img_hsv], [0], None, [180], [0, 180])\n",
    "        color_dominante = np.argmax(hist_h) / 179  # normalizado\n",
    "    else:\n",
    "        color_dominante = 0.0\n",
    "\n",
    "    # Armar el vector\n",
    "    vector = [\n",
    "        media,\n",
    "        std,\n",
    "        *hist,  # 4 bins\n",
    "        porc_oscuro,\n",
    "        porc_claro,\n",
    "        dens_bordes,\n",
    "        num_componentes,\n",
    "        area_max,\n",
    "        cx,\n",
    "        cy,\n",
    "        razon_aspecto,\n",
    "        color_dominante\n",
    "    ]\n",
    "\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28aaa76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_vector_caracteristico(carpeta_entrada, label='Default'):\n",
    "    if not os.path.exists(carpeta_entrada):\n",
    "        raise FileNotFoundError(f'La carpeta {carpeta_entrada} no existe.')\n",
    "    \n",
    "    datos_imagenes = cargar_imagenes(carpeta_entrada, label)\n",
    "    vec = []\n",
    "    for nombre, imagen in datos_imagenes:\n",
    "        vector = obtener_val_vector(imagen)\n",
    "        vec.append((label, vector))\n",
    "    \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbff128e",
   "metadata": {},
   "source": [
    "Obtención de los vectores y embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c46b770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings, shapes:\n",
      "(2173, 512)\n",
      "Labels:\n",
      "(2173,)\n"
     ]
    }
   ],
   "source": [
    "embeddings_esp = []\n",
    "embeddings_esp.extend(generar_embeddings('Espectrogramas_Audios_Buenos', 'Buena_pronunciacion'))\n",
    "embeddings_esp.extend(generar_embeddings('Espectrogramas_Audios_Malos', 'Mala_pronunciacion'))\n",
    "\n",
    "embeddings_label = [nombre for nombre, _ in embeddings_esp]\n",
    "solo_vectores = [vec for _, vec in embeddings_esp]\n",
    "embeddings_esp = np.array(solo_vectores)\n",
    "embeddings_label = np.array(embeddings_label)\n",
    "\n",
    "print(\"Embeddings, shapes:\")\n",
    "print(embeddings_esp.shape)\n",
    "print(\"Labels:\")\n",
    "print(embeddings_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e800cda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Caracteristico, shapes:\n",
      "(2173, 15)\n",
      "Labels:\n",
      "(2173,)\n"
     ]
    }
   ],
   "source": [
    "vector_esp = []\n",
    "vector_esp.extend(generar_vector_caracteristico('Espectrogramas_Audios_Buenos', 'Buena_pronunciacion'))\n",
    "vector_esp.extend(generar_vector_caracteristico('Espectrogramas_Audios_Malos', 'Mala_pronunciacion'))\n",
    "\n",
    "vector_label = [nombre for nombre, _ in vector_esp]\n",
    "solo_vectores = [vec for _, vec in vector_esp]\n",
    "vector_esp = np.array(solo_vectores)\n",
    "vector_label = np.array(vector_label)\n",
    "\n",
    "print(\"Vector Caracteristico, shapes:\")\n",
    "print(vector_esp.shape)\n",
    "print(\"Labels:\")\n",
    "print(vector_label.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
